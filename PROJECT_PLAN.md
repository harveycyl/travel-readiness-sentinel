# Travel Readiness Sentinel - Project Plan

## ğŸ¯ Project Overview

Transform a Python CLI validation tool into a production-grade microservice with observability and AI capabilities.

**Current Status:** Phase 2 Complete (Dockerized FastAPI)
**Next:** Phase 3 (Observability + Maintainability + AI Foundation)

---

## âœ… Phase 1: FastAPI Implementation (COMPLETE)

**Completed:** January 2026

**What was built:**
- REST API with FastAPI
- 4 endpoints: `/`, `/health`, `/validate`, `/upload`
- Pydantic models for validation
- Excel and YAML file parsing
- Swagger UI documentation at `/docs`
- 55 passing tests

**Key files:**
- `src/api.py` - FastAPI application
- `src/model.py` - Pydantic models
- `src/validation.py` - Business logic
- `src/excel_reader.py` - Excel parsing
- `src/schemas.py` - API schemas

---

## âœ… Phase 2: Docker Containerization (COMPLETE)

**Completed:** January 2026

**What was built:**
- Multi-stage Dockerfile (515MB image, 110MB content)
- Docker Compose for local development
- Non-root user for security
- Health checks
- `.dockerignore` for optimization

**Key files:**
- `Dockerfile` - Multi-stage build
- `docker-compose.yml` - Local dev setup
- `.dockerignore` - Build optimization

**Deployment:**
```bash
docker-compose up -d
# API available at http://localhost:8000
```

---

## ğŸš§ Phase 3: Observability + Maintainability + AI Foundation (IN PROGRESS)

**Goal:** Production-grade monitoring + clean architecture + prepare for AI

**Time estimate:** 12-15 hours

### Part A: Observability (6-8 hours)

#### A1. Structured Logging â­ ESSENTIAL
- JSON-formatted logs with context
- Track request IDs, source types (excel/yaml/ai)
- **Dependencies:** `python-json-logger>=2.0.0`
- **Time:** 3 hours

#### A2. Request/Response Middleware â­ ESSENTIAL
- Auto-log every API call
- Track duration, status codes
- **Time:** 1 hour

#### A3. Metrics Endpoint â­ IMPORTANT
- Prometheus-compatible metrics
- Track: request count, latency, error rate
- Separate metrics for AI vs manual inputs
- **Dependencies:** `prometheus-client>=0.19.0`
- **Time:** 2-3 hours

#### A4. Enhanced Health Checks
- Detailed component status
- Include metrics in health response
- **Time:** 1 hour

---

### Part B: Maintainability (4-5 hours)

#### B1. Code Organization â­ ESSENTIAL

**New structure:**
```
src/
â”œâ”€â”€ api.py                  # FastAPI app
â”œâ”€â”€ config.py              # Settings (AI-ready)
â”œâ”€â”€ middleware.py          # NEW: Logging
â”œâ”€â”€ metrics.py             # NEW: Prometheus
â”œâ”€â”€ logging_config.py      # NEW: Logging setup
â”‚
â”œâ”€â”€ core/                  # NEW: Core logic
â”‚   â”œâ”€â”€ model.py
â”‚   â”œâ”€â”€ validation.py
â”‚   â””â”€â”€ schemas.py
â”‚
â”œâ”€â”€ ingestion/            # NEW: Input processing (AI-ready!)
â”‚   â”œâ”€â”€ base.py           # Abstract base class
â”‚   â”œâ”€â”€ excel.py          # Excel reader (refactored)
â”‚   â”œâ”€â”€ yaml.py           # YAML reader
â”‚   â””â”€â”€ ai.py             # AI stub (Phase 4)
â”‚
â””â”€â”€ utils/
    â””â”€â”€ helpers.py
```

**Time:** 2-3 hours

#### B2. Abstract Base Classes â­ IMPORTANT

Create `IngestionSource` interface:
- Consistent API for all input types
- Easy to add AI without changing existing code
- **Time:** 2 hours

#### B3. Configuration Management
- Centralize settings in `config.py`
- AI settings prepared (disabled by default)
- **Time:** 30 minutes

---

### Part C: AI Foundation (2 hours)

#### C1. Unified Ingestion Pipeline â­ ESSENTIAL
- Single validation endpoint for all input types
- AI slots in seamlessly
- **Time:** 1 hour

#### C2. AI Placeholder
- Create stub `AIIngestion` class
- Documents future capability
- **Time:** 30 minutes

#### C3. Documentation
- Update README with planned AI features
- **Time:** 30 minutes

---

### Implementation Order

**Week 1: Observability (6-8 hours)**
1. Structured logging (A1)
2. Request middleware (A2)
3. Metrics endpoint (A3)

**Week 2: Maintainability + AI Prep (6-7 hours)**
4. Code organization (B1)
5. Abstract base classes (B2)
6. Unified pipeline (C1)
7. AI placeholder (C2)

---

### Dependencies to Add

```txt
# Observability
python-json-logger>=2.0.0
prometheus-client>=0.19.0

# AI (Phase 4 - commented out)
# openai>=1.0.0
```

---

## ğŸ”® Phase 4: AI Ingestion Layer (PLANNED)

**Goal:** Extract itineraries from unstructured text using LLM

**Time estimate:** 10 hours (thanks to Phase 3 foundation!)

**LLM Provider:** Google AI (Gemini) - using your existing Google AI Pro subscription!

### What Phase 3 Enables

With Phase 3 complete, Phase 4 becomes simple:

```python
# src/ingestion/ai.py
import google.generativeai as genai

class AIIngestion(IngestionSource):
    def __init__(self):
        genai.configure(api_key=settings.google_ai_api_key)
        self.model = genai.GenerativeModel('gemini-1.5-pro')
    
    async def parse(self, text: str) -> Dict[str, Any]:
        # Just implement this method!
        response = self.model.generate_content(
            EXTRACTION_PROMPT + text,
            generation_config={
                "response_mime_type": "application/json"  # Native JSON mode!
            }
        )
        return json.loads(response.text)
```

**Everything else already works:**
- âœ… Logging (tracks AI separately)
- âœ… Metrics (monitors AI success rate)
- âœ… Validation (same Pydantic models)
- âœ… API (unified endpoint)

**Why Google AI (Gemini)?**
- âœ… You have Google AI Pro subscription (no extra cost!)
- âœ… 2M token context window (handles long emails)
- âœ… Native JSON mode (perfect for structured extraction)
- âœ… Multimodal (can handle images if needed)

### Phase 4 Tasks

1. **Google AI Integration** (3 hours)
   - Install `google-generativeai` SDK
   - Configure Gemini 1.5 Pro
   - Prompt engineering for JSON extraction
   - Response parsing

2. **Safety Rails** (2 hours)
   - Validate LLM output with Pydantic
   - Handle hallucinations
   - Confidence scoring
   - Fallback to OpenAI (optional)

3. **AI Monitoring** (2 hours)
   - Track extraction success rate
   - Monitor token usage
   - Log LLM interactions
   - Compare Google AI vs manual accuracy

4. **Testing** (2 hours)
   - Test with various text formats (emails, PDFs, chat)
   - Edge cases (incomplete info, ambiguous dates)
   - Error handling

5. **Documentation** (1 hour)
   - API examples
   - Prompt templates
   - Configuration guide

### Dependencies

```txt
# Google AI (Primary - using your subscription!)
google-generativeai>=0.3.0

# OpenAI (Optional fallback)
# openai>=1.0.0
```

### Configuration

```python
# .env
AI_ENABLED=true
AI_PROVIDER=google  # or "openai"
GOOGLE_AI_API_KEY=your_api_key_here
GOOGLE_AI_MODEL=gemini-1.5-pro
```

---

## ï¿½ Phase 5: Gmail Integration via MCP (PLANNED)

**Goal:** Connect to Gmail using Model Context Protocol for email-based itinerary extraction

**Time estimate:** 8-10 hours

### What is MCP?

**Model Context Protocol** - A standardized way for AI applications to connect to external data sources (Gmail, Drive, Slack, etc.) without managing APIs directly.

### Architecture

```
TRS API â†’ MCP Client â†’ Gmail MCP Server â†’ Gmail API â†’ User's Emails
```

### Implementation Overview

1. **MCP Setup** (2h)
   - Install MCP client library
   - Configure Gmail MCP server
   - OAuth authentication flow

2. **Email Fetching** (2h)
   - Query travel-related emails via MCP
   - Filter by keywords (flight, hotel, booking, itinerary)
   - Return email list to user

3. **User Selection** (2h)
   - API endpoint to list emails
   - User selects relevant emails
   - Preview email content

4. **Email â†’ AI Extraction** (2h)
   - Retrieve email body via MCP
   - Pass to Phase 4 AI extraction
   - Validate and return results

5. **Testing & Documentation** (2h)

### Key Benefits of MCP

- âœ… **Standardized** - Works with any MCP-compatible service
- âœ… **Maintained** - Community-maintained servers
- âœ… **Secure** - OAuth handled properly
- âœ… **Extensible** - Easy to add Outlook, iCloud later
- âœ… **Less code** - Focus on business logic, not API integration

### New Dependencies

```txt
mcp>=1.0.0                    # Model Context Protocol client
google-auth>=2.0.0            # OAuth for Gmail
```

### New Endpoints

```
GET  /auth/gmail              # OAuth flow
GET  /emails                  # List travel emails
POST /extract-from-email      # Extract from selected email
```

---

## ï¿½ğŸ“Š Overall Progress

| Phase | Status | Time Spent | Deliverables |
|-------|--------|------------|--------------|
| Phase 1: FastAPI | âœ… Complete | ~20 hours | REST API, 4 endpoints, tests |
| Phase 2: Docker | âœ… Complete | ~10 hours | Containerized app, compose |
| Phase 3: Observability | ğŸš§ In Progress | 0/15 hours | Logging, metrics, clean code |
| Phase 4: AI Ingestion | ğŸ“‹ Planned | 0/10 hours | LLM extraction |
| Phase 5: Gmail MCP | ğŸ“‹ Planned | 0/10 hours | Email integration via MCP |

**Total estimated:** ~65 hours
**Completed:** ~30 hours (46%)
**Remaining:** ~35 hours (54%)

---

## ğŸ¯ Success Criteria

### Phase 3 Complete When:
1. âœ… All requests logged in JSON format
2. âœ… `/metrics` endpoint shows request count, latency, errors
3. âœ… Code organized with `core/` and `ingestion/` modules
4. âœ… Abstract base class for all input types
5. âœ… AI placeholder created and documented

### Phase 4 Complete When:
1. âœ… Can extract itinerary from plain text
2. âœ… LLM output validated by Pydantic
3. âœ… AI metrics tracked separately
4. âœ… Handles errors gracefully
5. âœ… Documented with examples

### Phase 5 Complete When:
1. âœ… MCP client connected to Gmail
2. âœ… Can fetch and filter travel emails
3. âœ… User can select emails via API
4. âœ… Selected emails extracted via Phase 4 AI
5. âœ… OAuth flow working securely

---

## ğŸ’¬ Open Questions

**For Phase 3:**
1. Prometheus metrics or simple JSON?
2. Logs to stdout (Docker best practice) or files?
3. Any code quality tools? (black, ruff, mypy?)

**For Phase 4:**
1. âœ… **LLM decided:** Google AI (Gemini 1.5 Pro) - using your subscription!
2. What text sources to prioritize? (email, chat, documents, PDFs?)
3. Should we add OpenAI as fallback option?

---

## ğŸ“ Notes

- Phase 3 makes Phase 4 much easier (10h instead of 20h+)
- Clean architecture allows easy extension
- All phases maintain backward compatibility
- Docker setup unchanged throughout

**Last updated:** January 10, 2026
**Current branch:** `phase-3-observability`
